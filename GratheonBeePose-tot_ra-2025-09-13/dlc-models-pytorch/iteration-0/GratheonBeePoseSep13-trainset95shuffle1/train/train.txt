2025-09-14 02:34:46 Training with configuration:
2025-09-14 02:34:46 data:
2025-09-14 02:34:46   bbox_margin: 20
2025-09-14 02:34:46   colormode: RGB
2025-09-14 02:34:46   inference:
2025-09-14 02:34:46     normalize_images: True
2025-09-14 02:34:46   train:
2025-09-14 02:34:46     affine:
2025-09-14 02:34:46       p: 0.5
2025-09-14 02:34:46       rotation: 30
2025-09-14 02:34:46       scaling: [0.5, 1.25]
2025-09-14 02:34:46       translation: 0
2025-09-14 02:34:46     crop_sampling:
2025-09-14 02:34:46       width: 448
2025-09-14 02:34:46       height: 448
2025-09-14 02:34:46       max_shift: 0.1
2025-09-14 02:34:46       method: hybrid
2025-09-14 02:34:46     gaussian_noise: 12.75
2025-09-14 02:34:46     motion_blur: True
2025-09-14 02:34:46     normalize_images: True
2025-09-14 02:34:46 device: auto
2025-09-14 02:34:46 metadata:
2025-09-14 02:34:46   project_path: /Users/artjom/git/entrance-observer-pose-deeplabcut/GratheonBeePose-tot_ra-2025-09-13
2025-09-14 02:34:46   pose_config_path: /Users/artjom/git/entrance-observer-pose-deeplabcut/GratheonBeePose-tot_ra-2025-09-13/dlc-models-pytorch/iteration-0/GratheonBeePoseSep13-trainset95shuffle2/train/pytorch_config.yaml
2025-09-14 02:34:46   bodyparts: ['head', 'thorax', 'abdomen', 'antenna-left', 'antenna-right', 'fore-leg-left', 'fore-leg-right', 'mid-leg-left', 'mid-leg-right', 'hind-leg-left', 'hind-leg-right', 'wing-left', 'wing-right']
2025-09-14 02:34:46   unique_bodyparts: []
2025-09-14 02:34:46   individuals: ['individual1', 'individual2', 'individual3', 'individual4', 'individual5', 'individual6', 'individual7', 'individual8', 'individual9', 'individual10']
2025-09-14 02:34:46   with_identity: False
2025-09-14 02:34:46 method: bu
2025-09-14 02:34:46 model:
2025-09-14 02:34:46   backbone:
2025-09-14 02:34:46     type: ResNet
2025-09-14 02:34:46     model_name: resnet50_gn
2025-09-14 02:34:46     output_stride: 16
2025-09-14 02:34:46     freeze_bn_stats: False
2025-09-14 02:34:46     freeze_bn_weights: False
2025-09-14 02:34:46   backbone_output_channels: 2048
2025-09-14 02:34:46   heads:
2025-09-14 02:34:46     bodypart:
2025-09-14 02:34:46       type: DLCRNetHead
2025-09-14 02:34:46       predictor:
2025-09-14 02:34:46         type: PartAffinityFieldPredictor
2025-09-14 02:34:46         num_animals: 10
2025-09-14 02:34:46         num_multibodyparts: 13
2025-09-14 02:34:46         num_uniquebodyparts: 0
2025-09-14 02:34:46         nms_radius: 5
2025-09-14 02:34:46         sigma: 1.0
2025-09-14 02:34:46         locref_stdev: 7.2801
2025-09-14 02:34:46         min_affinity: 0.05
2025-09-14 02:34:46         graph: [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [8, 9], [8, 10], [8, 11], [8, 12], [9, 10], [9, 11], [9, 12], [10, 11], [10, 12], [11, 12]]
2025-09-14 02:34:46         edges_to_keep: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77]
2025-09-14 02:34:46         apply_sigmoid: True
2025-09-14 02:34:46         clip_scores: False
2025-09-14 02:34:46       target_generator:
2025-09-14 02:34:46         type: SequentialGenerator
2025-09-14 02:34:46         generators: [{'type': 'HeatmapPlateauGenerator', 'num_heatmaps': 13, 'pos_dist_thresh': 17, 'heatmap_mode': 'KEYPOINT', 'gradient_masking': False, 'generate_locref': True, 'locref_std': 7.2801}, {'type': 'PartAffinityFieldGenerator', 'graph': [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [8, 9], [8, 10], [8, 11], [8, 12], [9, 10], [9, 11], [9, 12], [10, 11], [10, 12], [11, 12]], 'width': 20}]
2025-09-14 02:34:46       criterion:
2025-09-14 02:34:46         heatmap:
2025-09-14 02:34:46           type: WeightedBCECriterion
2025-09-14 02:34:46           weight: 1.0
2025-09-14 02:34:46         locref:
2025-09-14 02:34:46           type: WeightedHuberCriterion
2025-09-14 02:34:46           weight: 0.05
2025-09-14 02:34:46         paf:
2025-09-14 02:34:46           type: WeightedHuberCriterion
2025-09-14 02:34:46           weight: 0.1
2025-09-14 02:34:46       heatmap_config:
2025-09-14 02:34:46         channels: [2048, 13]
2025-09-14 02:34:46         kernel_size: [3]
2025-09-14 02:34:46         strides: [2]
2025-09-14 02:34:46       locref_config:
2025-09-14 02:34:46         channels: [2048, 26]
2025-09-14 02:34:46         kernel_size: [3]
2025-09-14 02:34:46         strides: [2]
2025-09-14 02:34:46       paf_config:
2025-09-14 02:34:46         channels: [2048, 156]
2025-09-14 02:34:46         kernel_size: [3]
2025-09-14 02:34:46         strides: [2]
2025-09-14 02:34:46       num_stages: 5
2025-09-14 02:34:46 net_type: resnet_50
2025-09-14 02:34:46 runner:
2025-09-14 02:34:46   type: PoseTrainingRunner
2025-09-14 02:34:46   gpus: None
2025-09-14 02:34:46   key_metric: test.mAP
2025-09-14 02:34:46   key_metric_asc: True
2025-09-14 02:34:46   eval_interval: 10
2025-09-14 02:34:46   optimizer:
2025-09-14 02:34:46     type: AdamW
2025-09-14 02:34:46     params:
2025-09-14 02:34:46       lr: 0.0005
2025-09-14 02:34:46   scheduler:
2025-09-14 02:34:46     type: LRListScheduler
2025-09-14 02:34:46     params:
2025-09-14 02:34:46       lr_list: [[0.0001], [1e-05]]
2025-09-14 02:34:46       milestones: [90, 120]
2025-09-14 02:34:46   snapshots:
2025-09-14 02:34:46     max_snapshots: 5
2025-09-14 02:34:46     save_epochs: 50
2025-09-14 02:34:46     save_optimizer_state: False
2025-09-14 02:34:46 train_settings:
2025-09-14 02:34:46   batch_size: 8
2025-09-14 02:34:46   dataloader_workers: 0
2025-09-14 02:34:46   dataloader_pin_memory: False
2025-09-14 02:34:46   display_iters: 1000
2025-09-14 02:34:46   epochs: 200
2025-09-14 02:34:46   seed: 42
2025-09-14 02:34:46 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-09-14 02:34:46 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-09-14 02:34:46 Data Transforms:
2025-09-14 02:34:46   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-09-14 02:34:46   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-09-14 02:34:46 Using 82 images and 5 for testing
2025-09-14 02:34:46 
Starting pose model training...
--------------------------------------------------
2025-09-14 02:35:12 Epoch 1/200 (lr=0.0005), train loss 0.06991
2025-09-14 02:35:44 Epoch 2/200 (lr=0.0005), train loss 0.01541
2025-09-14 02:36:00 Epoch 3/200 (lr=0.0005), train loss 0.01345
2025-09-14 02:36:16 Epoch 4/200 (lr=0.0005), train loss 0.01297
2025-09-14 02:36:33 Epoch 5/200 (lr=0.0005), train loss 0.01342
2025-09-14 02:36:49 Epoch 6/200 (lr=0.0005), train loss 0.01220
2025-09-14 02:37:05 Epoch 7/200 (lr=0.0005), train loss 0.01200
2025-09-14 02:37:21 Epoch 8/200 (lr=0.0005), train loss 0.01265
2025-09-14 02:37:37 Epoch 9/200 (lr=0.0005), train loss 0.01185
2025-09-14 02:37:52 Training for epoch 10 done, starting evaluation
2025-09-14 02:38:00 Epoch 10/200 (lr=0.0005), train loss 0.01272, valid loss 0.01149
2025-09-14 02:38:00 Model performance:
2025-09-14 02:38:00   metrics/test.rmse:         173.32
2025-09-14 02:38:00   metrics/test.rmse_pcutoff:    nan
2025-09-14 02:38:00   metrics/test.mAP:            0.00
2025-09-14 02:38:00   metrics/test.mAR:            0.00
2025-09-14 02:38:16 Epoch 11/200 (lr=0.0005), train loss 0.01196
2025-09-14 02:38:32 Epoch 12/200 (lr=0.0005), train loss 0.01326
2025-09-14 02:38:48 Epoch 13/200 (lr=0.0005), train loss 0.01223
2025-09-14 02:39:03 Epoch 14/200 (lr=0.0005), train loss 0.01012
2025-09-14 02:39:19 Epoch 15/200 (lr=0.0005), train loss 0.00851
2025-09-14 02:39:34 Epoch 16/200 (lr=0.0005), train loss 0.00946
2025-09-14 02:39:50 Epoch 17/200 (lr=0.0005), train loss 0.00836
2025-09-14 02:40:06 Epoch 18/200 (lr=0.0005), train loss 0.00883
2025-09-14 02:40:21 Epoch 19/200 (lr=0.0005), train loss 0.00845
2025-09-14 02:40:37 Training for epoch 20 done, starting evaluation
2025-09-14 02:40:40 Epoch 20/200 (lr=0.0005), train loss 0.00832, valid loss 0.00766
2025-09-14 02:40:40 Model performance:
2025-09-14 02:40:40   metrics/test.rmse:          55.03
2025-09-14 02:40:40   metrics/test.rmse_pcutoff:   6.42
2025-09-14 02:40:40   metrics/test.mAP:            2.03
2025-09-14 02:40:40   metrics/test.mAR:            4.67
2025-09-14 02:40:56 Epoch 21/200 (lr=0.0005), train loss 0.00867
2025-09-14 02:41:12 Epoch 22/200 (lr=0.0005), train loss 0.00829
2025-09-14 02:41:28 Epoch 23/200 (lr=0.0005), train loss 0.00828
2025-09-14 02:41:43 Epoch 24/200 (lr=0.0005), train loss 0.00720
2025-09-14 02:41:59 Epoch 25/200 (lr=0.0005), train loss 0.00830
2025-09-14 02:42:15 Epoch 26/200 (lr=0.0005), train loss 0.00753
2025-09-14 02:42:31 Epoch 27/200 (lr=0.0005), train loss 0.00710
2025-09-14 02:42:47 Epoch 28/200 (lr=0.0005), train loss 0.00750
2025-09-14 02:43:03 Epoch 29/200 (lr=0.0005), train loss 0.00816
2025-09-14 02:43:19 Training for epoch 30 done, starting evaluation
2025-09-14 02:43:23 Epoch 30/200 (lr=0.0005), train loss 0.00700, valid loss 0.00566
2025-09-14 02:43:23 Model performance:
2025-09-14 02:43:23   metrics/test.rmse:          71.28
2025-09-14 02:43:23   metrics/test.rmse_pcutoff:  54.89
2025-09-14 02:43:23   metrics/test.mAP:           16.86
2025-09-14 02:43:23   metrics/test.mAR:           21.33
2025-09-14 02:43:39 Epoch 31/200 (lr=0.0005), train loss 0.00704
2025-09-14 02:43:55 Epoch 32/200 (lr=0.0005), train loss 0.00654
2025-09-14 02:44:10 Epoch 33/200 (lr=0.0005), train loss 0.00647
2025-09-14 02:44:26 Epoch 34/200 (lr=0.0005), train loss 0.00578
2025-09-14 02:44:42 Epoch 35/200 (lr=0.0005), train loss 0.00615
2025-09-14 02:44:58 Epoch 36/200 (lr=0.0005), train loss 0.00606
2025-09-14 02:45:14 Epoch 37/200 (lr=0.0005), train loss 0.00677
2025-09-14 02:45:30 Epoch 38/200 (lr=0.0005), train loss 0.00581
2025-09-14 02:45:46 Epoch 39/200 (lr=0.0005), train loss 0.00642
2025-09-14 02:46:02 Training for epoch 40 done, starting evaluation
2025-09-14 02:46:06 Epoch 40/200 (lr=0.0005), train loss 0.00727, valid loss 0.00509
2025-09-14 02:46:06 Model performance:
2025-09-14 02:46:06   metrics/test.rmse:          38.01
2025-09-14 02:46:06   metrics/test.rmse_pcutoff:  24.19
2025-09-14 02:46:06   metrics/test.mAP:           18.74
2025-09-14 02:46:06   metrics/test.mAR:           32.67
2025-09-14 02:46:23 Epoch 41/200 (lr=0.0005), train loss 0.00644
2025-09-14 02:46:39 Epoch 42/200 (lr=0.0005), train loss 0.00655
2025-09-14 02:46:55 Epoch 43/200 (lr=0.0005), train loss 0.00600
2025-09-14 02:47:12 Epoch 44/200 (lr=0.0005), train loss 0.00570
2025-09-14 02:47:28 Epoch 45/200 (lr=0.0005), train loss 0.00558
2025-09-14 02:47:44 Epoch 46/200 (lr=0.0005), train loss 0.00591
2025-09-14 02:48:00 Epoch 47/200 (lr=0.0005), train loss 0.00491
2025-09-14 02:48:17 Epoch 48/200 (lr=0.0005), train loss 0.00537
2025-09-14 02:48:34 Epoch 49/200 (lr=0.0005), train loss 0.00508
2025-09-14 02:48:52 Training for epoch 50 done, starting evaluation
2025-09-14 02:48:58 Epoch 50/200 (lr=0.0005), train loss 0.00509, valid loss 0.00385
2025-09-14 02:48:58 Model performance:
2025-09-14 02:48:58   metrics/test.rmse:          26.45
2025-09-14 02:48:58   metrics/test.rmse_pcutoff:  13.82
2025-09-14 02:48:58   metrics/test.mAP:           35.31
2025-09-14 02:48:58   metrics/test.mAR:           42.67
2025-09-14 02:49:15 Epoch 51/200 (lr=0.0005), train loss 0.00496
2025-09-14 02:49:32 Epoch 52/200 (lr=0.0005), train loss 0.00527
2025-09-14 02:49:48 Epoch 53/200 (lr=0.0005), train loss 0.00527
2025-09-14 02:50:04 Epoch 54/200 (lr=0.0005), train loss 0.00487
2025-09-14 02:50:20 Epoch 55/200 (lr=0.0005), train loss 0.00493
2025-09-14 02:50:36 Epoch 56/200 (lr=0.0005), train loss 0.00463
2025-09-14 02:50:52 Epoch 57/200 (lr=0.0005), train loss 0.00506
2025-09-14 02:51:08 Epoch 58/200 (lr=0.0005), train loss 0.00487
2025-09-14 02:51:23 Epoch 59/200 (lr=0.0005), train loss 0.00464
2025-09-14 02:51:39 Training for epoch 60 done, starting evaluation
2025-09-14 02:51:43 Epoch 60/200 (lr=0.0005), train loss 0.00530, valid loss 0.00407
2025-09-14 02:51:43 Model performance:
2025-09-14 02:51:43   metrics/test.rmse:          91.02
2025-09-14 02:51:43   metrics/test.rmse_pcutoff:  83.50
2025-09-14 02:51:43   metrics/test.mAP:           39.58
2025-09-14 02:51:43   metrics/test.mAR:           46.67
2025-09-14 02:51:58 Epoch 61/200 (lr=0.0005), train loss 0.00452
2025-09-14 02:52:14 Epoch 62/200 (lr=0.0005), train loss 0.00399
2025-09-14 02:52:29 Epoch 63/200 (lr=0.0005), train loss 0.00476
2025-09-14 02:52:45 Epoch 64/200 (lr=0.0005), train loss 0.00498
2025-09-14 02:53:01 Epoch 65/200 (lr=0.0005), train loss 0.00427
2025-09-14 02:53:16 Epoch 66/200 (lr=0.0005), train loss 0.00485
2025-09-14 02:53:32 Epoch 67/200 (lr=0.0005), train loss 0.00459
2025-09-14 02:53:48 Epoch 68/200 (lr=0.0005), train loss 0.00429
2025-09-14 02:54:04 Epoch 69/200 (lr=0.0005), train loss 0.00425
2025-09-14 02:54:20 Training for epoch 70 done, starting evaluation
2025-09-14 02:54:23 Epoch 70/200 (lr=0.0005), train loss 0.00396, valid loss 0.00333
2025-09-14 02:54:23 Model performance:
2025-09-14 02:54:23   metrics/test.rmse:          69.44
2025-09-14 02:54:23   metrics/test.rmse_pcutoff:  55.17
2025-09-14 02:54:23   metrics/test.mAP:           53.19
2025-09-14 02:54:23   metrics/test.mAR:           61.33
2025-09-14 02:54:39 Epoch 71/200 (lr=0.0005), train loss 0.00397
2025-09-14 02:54:55 Epoch 72/200 (lr=0.0005), train loss 0.00356
2025-09-14 02:55:11 Epoch 73/200 (lr=0.0005), train loss 0.00442
2025-09-14 02:55:27 Epoch 74/200 (lr=0.0005), train loss 0.00450
2025-09-14 02:55:43 Epoch 75/200 (lr=0.0005), train loss 0.00369
2025-09-14 02:55:59 Epoch 76/200 (lr=0.0005), train loss 0.00365
2025-09-14 02:56:14 Epoch 77/200 (lr=0.0005), train loss 0.00391
2025-09-14 02:56:29 Epoch 78/200 (lr=0.0005), train loss 0.00386
2025-09-14 02:56:45 Epoch 79/200 (lr=0.0005), train loss 0.00464
2025-09-14 02:57:00 Training for epoch 80 done, starting evaluation
2025-09-14 02:57:04 Epoch 80/200 (lr=0.0005), train loss 0.00413, valid loss 0.00364
2025-09-14 02:57:04 Model performance:
2025-09-14 02:57:04   metrics/test.rmse:          37.36
2025-09-14 02:57:04   metrics/test.rmse_pcutoff:  31.96
2025-09-14 02:57:04   metrics/test.mAP:           57.68
2025-09-14 02:57:04   metrics/test.mAR:           67.33
2025-09-14 02:57:19 Epoch 81/200 (lr=0.0005), train loss 0.00399
2025-09-14 02:57:34 Epoch 82/200 (lr=0.0005), train loss 0.00367
2025-09-14 02:57:49 Epoch 83/200 (lr=0.0005), train loss 0.00360
2025-09-14 02:58:04 Epoch 84/200 (lr=0.0005), train loss 0.00366
2025-09-14 02:58:19 Epoch 85/200 (lr=0.0005), train loss 0.00346
2025-09-14 02:58:34 Epoch 86/200 (lr=0.0005), train loss 0.00371
2025-09-14 02:58:51 Epoch 87/200 (lr=0.0005), train loss 0.00399
2025-09-14 02:59:06 Epoch 88/200 (lr=0.0005), train loss 0.00424
2025-09-14 02:59:21 Epoch 89/200 (lr=0.0005), train loss 0.00398
2025-09-14 02:59:37 Training for epoch 90 done, starting evaluation
2025-09-14 02:59:41 Epoch 90/200 (lr=0.0001), train loss 0.00394, valid loss 0.00331
2025-09-14 02:59:41 Model performance:
2025-09-14 02:59:41   metrics/test.rmse:          34.14
2025-09-14 02:59:41   metrics/test.rmse_pcutoff:  30.82
2025-09-14 02:59:41   metrics/test.mAP:           66.09
2025-09-14 02:59:41   metrics/test.mAR:           73.33
2025-09-14 02:59:56 Epoch 91/200 (lr=0.0001), train loss 0.00317
2025-09-14 03:00:12 Epoch 92/200 (lr=0.0001), train loss 0.00323
2025-09-14 03:00:27 Epoch 93/200 (lr=0.0001), train loss 0.00332
2025-09-14 03:00:42 Epoch 94/200 (lr=0.0001), train loss 0.00329
2025-09-14 03:00:58 Epoch 95/200 (lr=0.0001), train loss 0.00295
2025-09-14 03:01:13 Epoch 96/200 (lr=0.0001), train loss 0.00355
2025-09-14 03:01:28 Epoch 97/200 (lr=0.0001), train loss 0.00328
2025-09-14 03:01:43 Epoch 98/200 (lr=0.0001), train loss 0.00330
2025-09-14 03:01:58 Epoch 99/200 (lr=0.0001), train loss 0.00297
2025-09-14 03:02:14 Training for epoch 100 done, starting evaluation
2025-09-14 03:02:17 Epoch 100/200 (lr=0.0001), train loss 0.00310, valid loss 0.00313
2025-09-14 03:02:17 Model performance:
2025-09-14 03:02:17   metrics/test.rmse:          12.06
2025-09-14 03:02:17   metrics/test.rmse_pcutoff:   7.43
2025-09-14 03:02:17   metrics/test.mAP:           69.41
2025-09-14 03:02:17   metrics/test.mAR:           76.67
2025-09-14 03:02:33 Epoch 101/200 (lr=0.0001), train loss 0.00303
2025-09-14 03:02:48 Epoch 102/200 (lr=0.0001), train loss 0.00315
2025-09-14 03:03:04 Epoch 103/200 (lr=0.0001), train loss 0.00318
2025-09-14 03:03:21 Epoch 104/200 (lr=0.0001), train loss 0.00298
2025-09-14 03:03:38 Epoch 105/200 (lr=0.0001), train loss 0.00291
2025-09-14 03:03:56 Epoch 106/200 (lr=0.0001), train loss 0.00270
2025-09-14 03:04:11 Epoch 107/200 (lr=0.0001), train loss 0.00286
2025-09-14 03:04:27 Epoch 108/200 (lr=0.0001), train loss 0.00311
2025-09-14 03:04:43 Epoch 109/200 (lr=0.0001), train loss 0.00293
2025-09-14 03:04:59 Training for epoch 110 done, starting evaluation
2025-09-14 03:05:01 Epoch 110/200 (lr=0.0001), train loss 0.00278, valid loss 0.00307
2025-09-14 03:05:01 Model performance:
2025-09-14 03:05:01   metrics/test.rmse:          31.03
2025-09-14 03:05:01   metrics/test.rmse_pcutoff:  30.05
2025-09-14 03:05:01   metrics/test.mAP:           66.54
2025-09-14 03:05:01   metrics/test.mAR:           74.67
2025-09-14 03:05:17 Epoch 111/200 (lr=0.0001), train loss 0.00336
2025-09-14 03:05:33 Epoch 112/200 (lr=0.0001), train loss 0.00299
2025-09-14 03:05:48 Epoch 113/200 (lr=0.0001), train loss 0.00260
2025-09-14 03:06:04 Epoch 114/200 (lr=0.0001), train loss 0.00253
2025-09-14 03:06:20 Epoch 115/200 (lr=0.0001), train loss 0.00300
2025-09-14 03:06:35 Epoch 116/200 (lr=0.0001), train loss 0.00318
2025-09-14 03:06:51 Epoch 117/200 (lr=0.0001), train loss 0.00318
2025-09-14 03:07:07 Epoch 118/200 (lr=0.0001), train loss 0.00299
2025-09-14 03:07:22 Epoch 119/200 (lr=0.0001), train loss 0.00335
2025-09-14 03:07:38 Training for epoch 120 done, starting evaluation
2025-09-14 03:07:41 Epoch 120/200 (lr=1e-05), train loss 0.00305, valid loss 0.00299
2025-09-14 03:07:41 Model performance:
2025-09-14 03:07:41   metrics/test.rmse:           6.79
2025-09-14 03:07:41   metrics/test.rmse_pcutoff:   6.25
2025-09-14 03:07:41   metrics/test.mAP:           69.96
2025-09-14 03:07:41   metrics/test.mAR:           77.33
2025-09-14 03:07:56 Epoch 121/200 (lr=1e-05), train loss 0.00268
2025-09-14 03:08:12 Epoch 122/200 (lr=1e-05), train loss 0.00264
2025-09-14 03:08:27 Epoch 123/200 (lr=1e-05), train loss 0.00281
2025-09-14 03:08:43 Epoch 124/200 (lr=1e-05), train loss 0.00247
2025-09-14 03:08:59 Epoch 125/200 (lr=1e-05), train loss 0.00252
2025-09-14 03:09:15 Epoch 126/200 (lr=1e-05), train loss 0.00255
2025-09-14 03:09:31 Epoch 127/200 (lr=1e-05), train loss 0.00257
2025-09-14 03:09:46 Epoch 128/200 (lr=1e-05), train loss 0.00248
2025-09-14 03:10:01 Epoch 129/200 (lr=1e-05), train loss 0.00213
2025-09-14 03:10:17 Training for epoch 130 done, starting evaluation
2025-09-14 03:10:19 Epoch 130/200 (lr=1e-05), train loss 0.00271, valid loss 0.00293
2025-09-14 03:10:19 Model performance:
2025-09-14 03:10:19   metrics/test.rmse:          11.90
2025-09-14 03:10:19   metrics/test.rmse_pcutoff:   7.54
2025-09-14 03:10:19   metrics/test.mAP:           65.77
2025-09-14 03:10:19   metrics/test.mAR:           74.67
2025-09-14 03:10:34 Epoch 131/200 (lr=1e-05), train loss 0.00252
2025-09-14 03:10:50 Epoch 132/200 (lr=1e-05), train loss 0.00314
2025-09-14 03:11:05 Epoch 133/200 (lr=1e-05), train loss 0.00267
2025-09-14 03:11:21 Epoch 134/200 (lr=1e-05), train loss 0.00313
2025-09-14 03:11:36 Epoch 135/200 (lr=1e-05), train loss 0.00229
2025-09-14 03:11:51 Epoch 136/200 (lr=1e-05), train loss 0.00265
2025-09-14 03:12:06 Epoch 137/200 (lr=1e-05), train loss 0.00262
2025-09-14 03:12:21 Epoch 138/200 (lr=1e-05), train loss 0.00253
2025-09-14 03:12:37 Epoch 139/200 (lr=1e-05), train loss 0.00286
2025-09-14 03:12:52 Training for epoch 140 done, starting evaluation
2025-09-14 03:12:54 Epoch 140/200 (lr=1e-05), train loss 0.00241, valid loss 0.00293
2025-09-14 03:12:54 Model performance:
2025-09-14 03:12:54   metrics/test.rmse:           9.10
2025-09-14 03:12:54   metrics/test.rmse_pcutoff:   7.76
2025-09-14 03:12:54   metrics/test.mAP:           69.86
2025-09-14 03:12:54   metrics/test.mAR:           78.67
2025-09-14 03:13:09 Epoch 141/200 (lr=1e-05), train loss 0.00290
2025-09-14 03:13:24 Epoch 142/200 (lr=1e-05), train loss 0.00250
2025-09-14 03:13:39 Epoch 143/200 (lr=1e-05), train loss 0.00276
2025-09-14 03:13:55 Epoch 144/200 (lr=1e-05), train loss 0.00289
2025-09-14 03:14:10 Epoch 145/200 (lr=1e-05), train loss 0.00278
2025-09-14 03:14:25 Epoch 146/200 (lr=1e-05), train loss 0.00263
2025-09-14 03:14:41 Epoch 147/200 (lr=1e-05), train loss 0.00283
2025-09-14 03:14:56 Epoch 148/200 (lr=1e-05), train loss 0.00317
2025-09-14 03:15:11 Epoch 149/200 (lr=1e-05), train loss 0.00246
2025-09-14 03:15:27 Training for epoch 150 done, starting evaluation
2025-09-14 03:15:30 Epoch 150/200 (lr=1e-05), train loss 0.00299, valid loss 0.00298
2025-09-14 03:15:30 Model performance:
2025-09-14 03:15:30   metrics/test.rmse:          10.54
2025-09-14 03:15:30   metrics/test.rmse_pcutoff:   8.32
2025-09-14 03:15:30   metrics/test.mAP:           64.43
2025-09-14 03:15:30   metrics/test.mAR:           73.33
2025-09-14 03:15:47 Epoch 151/200 (lr=1e-05), train loss 0.00292
2025-09-14 03:16:04 Epoch 152/200 (lr=1e-05), train loss 0.00270
2025-09-14 03:16:21 Epoch 153/200 (lr=1e-05), train loss 0.00272
2025-09-14 03:16:37 Epoch 154/200 (lr=1e-05), train loss 0.00318
2025-09-14 03:16:53 Epoch 155/200 (lr=1e-05), train loss 0.00278
2025-09-14 03:17:09 Epoch 156/200 (lr=1e-05), train loss 0.00274
2025-09-14 03:17:24 Epoch 157/200 (lr=1e-05), train loss 0.00253
2025-09-14 03:17:39 Epoch 158/200 (lr=1e-05), train loss 0.00274
2025-09-14 03:17:55 Epoch 159/200 (lr=1e-05), train loss 0.00292
2025-09-14 03:18:11 Training for epoch 160 done, starting evaluation
2025-09-14 03:18:12 Epoch 160/200 (lr=1e-05), train loss 0.00323, valid loss 0.00296
2025-09-14 03:18:12 Model performance:
2025-09-14 03:18:12   metrics/test.rmse:          10.19
2025-09-14 03:18:12   metrics/test.rmse_pcutoff:   8.37
2025-09-14 03:18:12   metrics/test.mAP:           66.35
2025-09-14 03:18:12   metrics/test.mAR:           74.67
2025-09-14 03:18:28 Epoch 161/200 (lr=1e-05), train loss 0.00285
2025-09-14 03:18:43 Epoch 162/200 (lr=1e-05), train loss 0.00274
2025-09-14 03:18:58 Epoch 163/200 (lr=1e-05), train loss 0.00293
2025-09-14 03:19:13 Epoch 164/200 (lr=1e-05), train loss 0.00293
2025-09-14 03:19:27 Epoch 165/200 (lr=1e-05), train loss 0.00232
2025-09-14 03:19:43 Epoch 166/200 (lr=1e-05), train loss 0.00286
2025-09-14 03:19:58 Epoch 167/200 (lr=1e-05), train loss 0.00281
2025-09-14 03:20:13 Epoch 168/200 (lr=1e-05), train loss 0.00295
2025-09-14 03:20:28 Epoch 169/200 (lr=1e-05), train loss 0.00270
2025-09-14 03:20:44 Training for epoch 170 done, starting evaluation
2025-09-14 03:20:47 Epoch 170/200 (lr=1e-05), train loss 0.00239, valid loss 0.00293
2025-09-14 03:20:47 Model performance:
2025-09-14 03:20:47   metrics/test.rmse:           9.12
2025-09-14 03:20:47   metrics/test.rmse_pcutoff:   7.83
2025-09-14 03:20:47   metrics/test.mAP:           70.15
2025-09-14 03:20:47   metrics/test.mAR:           78.67
2025-09-14 03:21:02 Epoch 171/200 (lr=1e-05), train loss 0.00279
2025-09-14 03:21:17 Epoch 172/200 (lr=1e-05), train loss 0.00281
2025-09-14 03:21:32 Epoch 173/200 (lr=1e-05), train loss 0.00290
2025-09-14 03:21:47 Epoch 174/200 (lr=1e-05), train loss 0.00266
2025-09-14 03:22:03 Epoch 175/200 (lr=1e-05), train loss 0.00262
2025-09-14 03:22:18 Epoch 176/200 (lr=1e-05), train loss 0.00317
2025-09-14 03:22:33 Epoch 177/200 (lr=1e-05), train loss 0.00296
2025-09-14 03:22:48 Epoch 178/200 (lr=1e-05), train loss 0.00264
2025-09-14 03:23:03 Epoch 179/200 (lr=1e-05), train loss 0.00234
2025-09-14 03:23:18 Training for epoch 180 done, starting evaluation
2025-09-14 03:23:20 Epoch 180/200 (lr=1e-05), train loss 0.00255, valid loss 0.00294
2025-09-14 03:23:20 Model performance:
2025-09-14 03:23:20   metrics/test.rmse:           9.87
2025-09-14 03:23:20   metrics/test.rmse_pcutoff:   6.60
2025-09-14 03:23:20   metrics/test.mAP:           63.64
2025-09-14 03:23:20   metrics/test.mAR:           73.33
2025-09-14 03:23:35 Epoch 181/200 (lr=1e-05), train loss 0.00270
2025-09-14 03:23:50 Epoch 182/200 (lr=1e-05), train loss 0.00234
2025-09-14 03:24:05 Epoch 183/200 (lr=1e-05), train loss 0.00265
2025-09-14 03:24:20 Epoch 184/200 (lr=1e-05), train loss 0.00257
2025-09-14 03:24:35 Epoch 185/200 (lr=1e-05), train loss 0.00278
2025-09-14 03:24:50 Epoch 186/200 (lr=1e-05), train loss 0.00307
2025-09-14 03:25:05 Epoch 187/200 (lr=1e-05), train loss 0.00252
2025-09-14 03:25:20 Epoch 188/200 (lr=1e-05), train loss 0.00316
2025-09-14 03:25:35 Epoch 189/200 (lr=1e-05), train loss 0.00291
2025-09-14 03:25:50 Training for epoch 190 done, starting evaluation
2025-09-14 03:25:52 Epoch 190/200 (lr=1e-05), train loss 0.00265, valid loss 0.00290
2025-09-14 03:25:52 Model performance:
2025-09-14 03:25:52   metrics/test.rmse:           8.60
2025-09-14 03:25:52   metrics/test.rmse_pcutoff:   7.83
2025-09-14 03:25:52   metrics/test.mAP:           68.20
2025-09-14 03:25:52   metrics/test.mAR:           77.33
2025-09-14 03:26:07 Epoch 191/200 (lr=1e-05), train loss 0.00260
2025-09-14 03:26:22 Epoch 192/200 (lr=1e-05), train loss 0.00278
2025-09-14 03:26:38 Epoch 193/200 (lr=1e-05), train loss 0.00251
2025-09-14 03:26:52 Epoch 194/200 (lr=1e-05), train loss 0.00251
2025-09-14 03:27:07 Epoch 195/200 (lr=1e-05), train loss 0.00251
2025-09-14 03:27:22 Epoch 196/200 (lr=1e-05), train loss 0.00210
2025-09-14 03:27:37 Epoch 197/200 (lr=1e-05), train loss 0.00264
2025-09-14 03:27:52 Epoch 198/200 (lr=1e-05), train loss 0.00289
2025-09-14 03:28:08 Epoch 199/200 (lr=1e-05), train loss 0.00278
2025-09-14 03:28:23 Training for epoch 200 done, starting evaluation
2025-09-14 03:28:26 Epoch 200/200 (lr=1e-05), train loss 0.00241, valid loss 0.00294
2025-09-14 03:28:26 Model performance:
2025-09-14 03:28:26   metrics/test.rmse:          62.60
2025-09-14 03:28:26   metrics/test.rmse_pcutoff:  56.85
2025-09-14 03:28:26   metrics/test.mAP:           69.38
2025-09-14 03:28:26   metrics/test.mAR:           76.67
